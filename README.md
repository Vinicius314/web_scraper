# Web Scraper

Este projeto tem como objetivo automatizar a coleta de informaÃ§Ãµes de pÃ¡ginas web. Ele permite extrair dados estruturados como textos, links, imagens e tabelas de forma rÃ¡pida e eficiente, salvando os resultados em arquivos CSV ou JSON.

## ğŸš€ Funcionalidades

- Coleta automÃ¡tica de dados a partir de URLs.
- ExtraÃ§Ã£o de informaÃ§Ãµes como:
  - TÃ­tulos e descriÃ§Ãµes
  - Links e imagens
  - Tabelas e listas
- ExportaÃ§Ã£o dos dados para:
  - `.csv`
  - `.json`

## ğŸ› ï¸ Tecnologias utilizadas

- Python 3.x
- `requests` â€“ Para requisiÃ§Ãµes HTTP
- `BeautifulSoup` â€“ Para parsing HTML
- `pandas` â€“ Para estruturaÃ§Ã£o e exportaÃ§Ã£o dos dados

## ğŸ“ Estrutura do Projeto

web_scraper/
-â”œâ”€â”€ main.py # Script principal de execuÃ§Ã£o
-â”œâ”€â”€ scraper.py # FunÃ§Ãµes de scraping
-â”œâ”€â”€ utils.py # FunÃ§Ãµes auxiliares (ex: limpeza de dados)
-â”œâ”€â”€ requirements.txt # Bibliotecas necessÃ¡rias
-â”œâ”€â”€ README.md # DescriÃ§Ã£o do projeto
-â””â”€â”€ output/ # Pasta com os resultados exportados


## â–¶ï¸ Como usar

1. **Clone o repositÃ³rio:**
   ```bash
   git clone https://github.com/seu-usuario/web_scraper.git
   cd web_scraper
